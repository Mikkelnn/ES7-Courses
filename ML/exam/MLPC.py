# %%
import numpy as np
from scipy.io import loadmat
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.neural_network import MLPClassifier as MLPC
import time
import warnings

warnings.simplefilter(action='ignore') #Ignore warnings

# %% [markdown]
# # Exercise lecture 8 - Multilayer Perceptron
# Develop an MLP for the MNIST
# database by using the dimension-reduced data from your work on Exercises 2 and 3. You can download the LDA projected data here.
# Further, you can use 10-, 20- and 30-dimensional data generated by PCA and compare
# their performance (at the same time, try various MLP architectures).

# %% [markdown]
# ## Loading data

# %%
def create_complete_datasets(data_dict):
    '''
    Function for creating complete training and test sets containing
    all classes.
    '''
    #Empty list
    trainset = []
    traintargets =[]
    testset = []
    testtargets =[]
    
    #For each class
    for i in range(10):
        trainset.append(data_dict["train%d"%i])
        traintargets.append(np.full(len(data_dict["train%d"%i]),i))
        testset.append(data_dict["test%d"%i])
        testtargets.append(np.full(len(data_dict["test%d"%i]),i))
    
    #Concatenate into to complete datasets
    trainset = np.concatenate(trainset)
    traintargets = np.concatenate(traintargets)
    testset = np.concatenate(testset)
    testtargets = np.concatenate(testtargets)
    return trainset, traintargets, testset, testtargets

file = "mnist_all.mat"
data = loadmat(file)

#Complete training and test sets
train_set, train_targets, test_set, test_targets = create_complete_datasets(data)
train_set = train_set/255
test_set = test_set/255
classes = np.arange(10)

# %% [markdown]
# ## Generating PCA/LDA data
# From previous exercises we already know how to use PCA/LDA.
# We first fit a PCA/LDA model to our training data, and then transform the training and test data using this model, to get a dimensionality reduced data set.

n_components = 9

transform_pca = PCA(n_components=n_components).fit(train_set)
pca_reduced_train = transform_pca.transform(train_set)

transform_LDA = LDA(n_components=n_components).fit(train_set, train_targets)
lda_reduced_train = transform_LDA.transform(train_set)

# %% [markdown]
# ## Creating and Training MLP
# Sklearn has a multilayer perceptron classifier which we can use:
# https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html 
# 
# To use it, we need to choose how many layers we would like to use and the size of each hidden layer. 
# We can also choose which non-linear activation function to use and what optimizer/solver to use.
# You can set a maximum iteration number as well (to limit compute time).

network = MLPC(hidden_layer_sizes=(10, 10), activation='relu', solver='adam', max_iter=200)

LDA_MLPC = network.fit(lda_reduced_train, train_targets)
pca_MLPC = network.fit(pca_reduced_train, train_targets)

# %% [markdown]
# ## Evaluating MLP on test set

# %%
# Transform test data
pca_reduced_test = transform_pca.transform(test_set)
lda_reduced_test = transform_LDA.transform(test_set)

# Make predictions
lda_mlpc_predictions = LDA_MLPC.predict(lda_reduced_test)
pca_mlpc_predictions = pca_MLPC.predict(pca_reduced_test)

# Compute accuracy
from sklearn.metrics import accuracy_score

lda_mlpc_accuracy = accuracy_score(test_targets, lda_mlpc_predictions)
pca_mlpc_accuracy = accuracy_score(test_targets, pca_mlpc_predictions)

# %% [markdown]
# ## Plotting Confusion Matrices

# %%
# Compute confusion matrices
lda_mlpc_cm = confusion_matrix(test_targets, lda_mlpc_predictions)
pca_mlpc_cm = confusion_matrix(test_targets, pca_mlpc_predictions)

# Plot confusion matrices
fig, axes = plt.subplots(1, 2, figsize=(16, 6))

# LDA MLPC Confusion Matrix
disp_lda = ConfusionMatrixDisplay(confusion_matrix=lda_mlpc_cm, display_labels=np.arange(10))
disp_lda.plot(ax=axes[0], cmap='Blues', values_format='d')
axes[0].set_title(f'LDA + MLPC\nAccuracy: {lda_mlpc_accuracy*100:.2f}%')

# PCA MLPC Confusion Matrix
disp_pca = ConfusionMatrixDisplay(confusion_matrix=pca_mlpc_cm, display_labels=np.arange(10))
disp_pca.plot(ax=axes[1], cmap='Blues', values_format='d')
axes[1].set_title(f'PCA + MLPC\nAccuracy: {pca_mlpc_accuracy*100:.2f}%')

plt.tight_layout()
plt.show()

# Print summary
print("\n=== Confusion Matrix Summary ===")
print(f"LDA + MLPC Accuracy: {lda_mlpc_accuracy*100:.2f}%")
print(f"PCA + MLPC Accuracy: {pca_mlpc_accuracy*100:.2f}%")
